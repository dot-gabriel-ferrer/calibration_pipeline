# Author: Elías Gabriel Ferrer Jorge

"""
Step 5: Bias Model Evaluation Against Real Master Frames

This module compares synthetic bias frames (generated by a temperature-dependent model)
against real master bias frames, to evaluate model performance.

It computes pixel-wise:
  - MAE (Mean Absolute Error)
  - MAPE (Mean Absolute Percentage Error)

It also generates diagnostic visualizations and a summary plot of model accuracy
across temperatures.
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from astropy.io import fits
from tqdm import tqdm
from .step4_generate_synthetic_bias import generate_synthetic_bias

def evaluate_model(a_map: np.ndarray, b_map: np.ndarray,
                   master_bias_dict: dict, output_dir: str,
                   save_fits: bool = False):
    """
    Evaluate the bias model against real master bias frames.

    Parameters:
    ------------
    a_map : np.ndarray
        Intercept map from linear model (bias offset per pixel).

    b_map : np.ndarray
        Temperature slope map (bias sensitivity per pixel).

    master_bias_dict : dict[float, np.ndarray]
        Mapping from temperature to real master bias arrays.

    output_dir : str
        Directory where evaluation results (plots, optional FITS) will be saved.

    save_fits : bool, optional
        If True, also saves synthetic bias, MAE, and MAPE as FITS files.
    """
    print("\n[Step 5] Evaluating bias model against real master biases...")
    os.makedirs(output_dir, exist_ok=True)

    avg_mae_list = []
    std_mae_list = []
    avg_mape_list = []
    std_mape_list = []
    temperature_list = []

    for temp in tqdm(sorted(master_bias_dict.keys()), desc="Evaluating", ncols=80):
        real_bias = master_bias_dict[temp]
        synthetic = generate_synthetic_bias(a_map, b_map, temp)

        mae = np.abs(real_bias - synthetic)
        mape = np.abs((real_bias - synthetic) / (real_bias + 1e-8)) * 100

        if save_fits:
            fits.writeto(os.path.join(output_dir, f"synthetic_bias_{temp:.1f}C.fits"),
                         synthetic.astype(np.float32), overwrite=True)
            fits.writeto(os.path.join(output_dir, f"mae_{temp:.1f}C.fits"),
                         mae.astype(np.float32), overwrite=True)
            fits.writeto(os.path.join(output_dir, f"mape_{temp:.1f}C.fits"),
                         mape.astype(np.float32), overwrite=True)

        def plot_and_save(data, title, fname, cmap='viridis', vmax=None):
            plt.figure(figsize=(6, 5))
            plt.imshow(data, cmap=cmap, vmax=vmax)
            plt.title(title)
            plt.colorbar()
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, fname), dpi=150)
            plt.close()

        plot_and_save(real_bias, f"Real Bias @ {temp:.1f}°C", f"real_bias_{temp:.1f}C.png")
        plot_and_save(synthetic, f"Synthetic Bias @ {temp:.1f}°C", f"synthetic_bias_{temp:.1f}C.png")
        plot_and_save(mae, f"MAE @ {temp:.1f}°C", f"mae_{temp:.1f}C.png", cmap='hot')
        plot_and_save(mape, f"MAPE @ {temp:.1f}°C", f"mape_{temp:.1f}C.png", cmap='hot', vmax=100)

        avg_mae_list.append(np.nanmean(mae))
        std_mae_list.append(np.nanstd(mae))
        avg_mape_list.append(np.nanmean(mape))
        std_mape_list.append(np.nanstd(mape))
        temperature_list.append(temp)

    plt.figure(figsize=(8, 5))
    plt.errorbar(temperature_list, avg_mae_list, yerr=std_mae_list, fmt='-o', label='MAE (ADU)')
    plt.errorbar(temperature_list, avg_mape_list, yerr=std_mape_list, fmt='-s', label='MAPE (%)')
    plt.xlabel("Temperature (°C)")
    plt.ylabel("Error")
    plt.title("Bias Model Evaluation Summary")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "evaluation_summary.png"), dpi=150)
    plt.close()

    print(f"[Step 5] Evaluation completed and saved to '{output_dir}'\n")
